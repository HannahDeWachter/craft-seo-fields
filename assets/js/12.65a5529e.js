(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{365:function(t,e,o){"use strict";o.r(e);var s=o(42),a=Object(s.a)({},(function(){var t=this,e=t.$createElement,o=t._self._c||e;return o("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[o("h1",{attrs:{id:"robots-txt"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#robots-txt"}},[t._v("#")]),t._v(" Robots.txt")]),t._v(" "),o("h3",{attrs:{id:"default"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#default"}},[t._v("#")]),t._v(" Default")]),t._v(" "),o("p",[t._v("When you install the plugin, it enabled the robots.txt by default, using "),o("a",{attrs:{href:"https://github.com/studioespresso/craft-seo-fields/blob/master/src/templates/_placeholder/_robots.twig",target:"_blank",rel:"noopener noreferrer"}},[t._v("this template"),o("OutboundLink")],1),t._v(".")]),t._v(" "),o("p",[t._v("Based on the environment you've set in your site's "),o("code",[t._v(".env")]),t._v(" file, it will only allow indexing on "),o("code",[t._v("live")]),t._v(" or "),o("code",[t._v("production")]),t._v(" environments and block indexing on all others.")]),t._v(" "),o("p",[t._v("You can modify the template with your own enviroments, conditions and settings in the CP.")]),t._v(" "),o("p",[t._v("⚠️ Note that this will not stop Google from indexing your staging/dev site if and when someone else has a link to it. Always add another level of authentication to make sure Google can't index it.")]),t._v(" "),o("h3",{attrs:{id:"multisite"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#multisite"}},[t._v("#")]),t._v(" Multisite")]),t._v(" "),o("p",[t._v("By default, each site in your Craft install will get the same "),o("code",[t._v("robots.txt")]),t._v(". If you need the option to change these per site, you can add "),o("code",[t._v('"robotsPerSite" => true')]),t._v(" to "),o("code",[t._v("config/seo-fields.php")]),t._v(".")]),t._v(" "),o("p",[t._v("With that set, refresh the robots settings page and you'll see a sites dropdown at the top so you can switch sites and save a robots.txt for each.")])])}),[],!1,null,null,null);e.default=a.exports}}]);